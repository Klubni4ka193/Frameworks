{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа 1: Проведение исследований с алгоритмом KNN\n",
    "**Наборы данных:**\n",
    "- Классификация: Bookstore Financial Dataset (Calgary) — Kaggle dataset by Gabrielle Charlton.\n",
    "- Регрессия: Market Trend & External Factors Dataset — Kaggle dataset by Kundan Bedmutha.\n",
    "\n",
    "**Инструкции по данным:**\n",
    "1. Скачайте нужные CSV-файлы с Kaggle и положите их в папку `data/` рядом с этим ноутбуком.\n",
    "   - Рекомендуемые имена файлов:\n",
    "     - `data/bookstore.csv` — данные для классификации (Bookstore Financial Dataset). Подробнее: https://www.kaggle.com/datasets/gabriellecharlton/bookstore-financial-dataset-2019-2024-calgary. \n",
    "     - `data/market_trend.csv` — данные для регрессии (Market Trend & External Factors). Подробнее: https://www.kaggle.com/datasets/kundanbedmutha/market-trend-and-external-factors-dataset.\n",
    "2. Если вы используете Kaggle API, положите `kaggle.json` в `~/.kaggle/` и используйте `kaggle datasets download`.\n",
    "\n",
    "**Задание по ноутбуку соответствует документу с лабораторными:** см. загруженный файл `Лабы_фреймворки.docx`.\n",
    "\n",
    "---\n"
   ],
   "id": "57b4350b6bca2551"
  },
  {
   "cell_type": "code",
   "id": "8aa9bb2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T08:54:18.221574Z",
     "start_time": "2025-12-09T08:54:17.196381Z"
    }
   },
   "source": [
    "# Импорт стандартных библиотек и вспомогательных функций\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Импорт моделей sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "RND = 42\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f1efa288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T08:54:20.197018Z",
     "start_time": "2025-12-09T08:54:20.125349Z"
    }
   },
   "source": [
    "# Загрузка данных\n",
    "bookstore_path = 'data/bookstore.csv'   # классификация\n",
    "market_path = 'data/market_trend.csv'   # регрессия\n",
    "\n",
    "# Попытка загрузки — если файла нет, появится понятная ошибка.\n",
    "try:\n",
    "    df_book = pd.read_csv(bookstore_path)\n",
    "    print('Bookstore dataset loaded, shape:', df_book.shape)\n",
    "except Exception as e:\n",
    "    print('Не удалось загрузить bookstore.csv — проверьте путь. Ошибка:', e)\n",
    "    df_book = None\n",
    "\n",
    "try:\n",
    "    df_market = pd.read_csv(market_path)\n",
    "    print('Market dataset loaded, shape:', df_market.shape)\n",
    "except Exception as e:\n",
    "    print('Не удалось загрузить market_trend.csv — проверьте путь. Ошибка:', e)\n",
    "    df_market = None\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bookstore dataset loaded, shape: (21566, 10)\n",
      "Market dataset loaded, shape: (30000, 14)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8e95d353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T08:54:23.817230Z",
     "start_time": "2025-12-09T08:54:23.772304Z"
    }
   },
   "source": [
    "# Быстрая разведочная аналитика (EDA)\n",
    "# Смотрим первые строки, пропуски и типы признаков.\n",
    "if df_book is not None:\n",
    "    display(df_book.head())\n",
    "    print('\\nBookstore info:')\n",
    "    print(df_book.info())\n",
    "    print('\\nMissing values (book):\\n', df_book.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "if df_market is not None:\n",
    "    display(df_market.head())\n",
    "    print('\\nMarket info:')\n",
    "    print(df_market.info())\n",
    "    print('\\nMissing values (market):\\n', df_market.isnull().sum().sort_values(ascending=False).head(10))\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        month    from      to     sku  qty  unit_cost  unit_price  \\\n",
       "0  2019-01-01  YYC-WH  YYC-DT  BK1000   19       8.09       18.92   \n",
       "1  2019-01-01  YYC-WH  YYC-NW  BK1000   10       8.09       18.92   \n",
       "2  2019-01-01  YYC-WH  YYC-SE  BK1000    7       8.09       18.92   \n",
       "3  2019-01-01  YYC-WH  YYC-DT  BK1001   21      10.75       24.49   \n",
       "4  2019-01-01  YYC-WH  YYC-NW  BK1001   13      10.75       24.49   \n",
       "\n",
       "   extended_cost  extended_retail              dataset  \n",
       "0         153.71           359.48  bookstore_inventory  \n",
       "1          80.90           189.20  bookstore_inventory  \n",
       "2          56.63           132.44  bookstore_inventory  \n",
       "3         225.75           514.29  bookstore_inventory  \n",
       "4         139.75           318.37  bookstore_inventory  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>sku</th>\n",
       "      <th>qty</th>\n",
       "      <th>unit_cost</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>extended_cost</th>\n",
       "      <th>extended_retail</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>YYC-WH</td>\n",
       "      <td>YYC-DT</td>\n",
       "      <td>BK1000</td>\n",
       "      <td>19</td>\n",
       "      <td>8.09</td>\n",
       "      <td>18.92</td>\n",
       "      <td>153.71</td>\n",
       "      <td>359.48</td>\n",
       "      <td>bookstore_inventory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>YYC-WH</td>\n",
       "      <td>YYC-NW</td>\n",
       "      <td>BK1000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.09</td>\n",
       "      <td>18.92</td>\n",
       "      <td>80.90</td>\n",
       "      <td>189.20</td>\n",
       "      <td>bookstore_inventory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>YYC-WH</td>\n",
       "      <td>YYC-SE</td>\n",
       "      <td>BK1000</td>\n",
       "      <td>7</td>\n",
       "      <td>8.09</td>\n",
       "      <td>18.92</td>\n",
       "      <td>56.63</td>\n",
       "      <td>132.44</td>\n",
       "      <td>bookstore_inventory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>YYC-WH</td>\n",
       "      <td>YYC-DT</td>\n",
       "      <td>BK1001</td>\n",
       "      <td>21</td>\n",
       "      <td>10.75</td>\n",
       "      <td>24.49</td>\n",
       "      <td>225.75</td>\n",
       "      <td>514.29</td>\n",
       "      <td>bookstore_inventory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>YYC-WH</td>\n",
       "      <td>YYC-NW</td>\n",
       "      <td>BK1001</td>\n",
       "      <td>13</td>\n",
       "      <td>10.75</td>\n",
       "      <td>24.49</td>\n",
       "      <td>139.75</td>\n",
       "      <td>318.37</td>\n",
       "      <td>bookstore_inventory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bookstore info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21566 entries, 0 to 21565\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   month            21566 non-null  object \n",
      " 1   from             21566 non-null  object \n",
      " 2   to               21566 non-null  object \n",
      " 3   sku              21566 non-null  object \n",
      " 4   qty              21566 non-null  int64  \n",
      " 5   unit_cost        21566 non-null  float64\n",
      " 6   unit_price       21566 non-null  float64\n",
      " 7   extended_cost    21566 non-null  float64\n",
      " 8   extended_retail  21566 non-null  float64\n",
      " 9   dataset          21566 non-null  object \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "\n",
      "Missing values (book):\n",
      " month              0\n",
      "from               0\n",
      "to                 0\n",
      "sku                0\n",
      "qty                0\n",
      "unit_cost          0\n",
      "unit_price         0\n",
      "extended_cost      0\n",
      "extended_retail    0\n",
      "dataset            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         Date  Open_Price  Close_Price  High_Price  Low_Price    Volume  \\\n",
       "0  1902-09-08      100.00       100.50      100.63      99.35   2334489   \n",
       "1  1902-09-09      100.50       102.02      102.30      99.49  10626850   \n",
       "2  1902-09-10      102.02       101.55      102.56     101.09   9884633   \n",
       "3  1902-09-11      101.55       101.08      104.16     100.13   9405648   \n",
       "4  1902-09-12      101.08        98.65      101.69      98.39   5247581   \n",
       "\n",
       "   Daily_Return_Pct  Volatility_Range  VIX_Close  Economic_News_Flag  \\\n",
       "0            0.0000              1.28      31.44                   0   \n",
       "1            1.5124              2.81      27.99                   1   \n",
       "2           -0.4607              1.47      21.27                   1   \n",
       "3           -0.4628              4.03      48.86                   1   \n",
       "4           -2.4040              3.30      15.78                   1   \n",
       "\n",
       "   Sentiment_Score  Federal_Rate_Change_Flag  GeoPolitical_Risk_Score  \\\n",
       "0           -0.413                         0                    61.60   \n",
       "1           -0.384                         1                    69.49   \n",
       "2            0.591                         0                    67.41   \n",
       "3            0.599                         1                    50.91   \n",
       "4           -0.081                         1                    23.00   \n",
       "\n",
       "   Currency_Index  \n",
       "0           98.88  \n",
       "1           93.43  \n",
       "2           84.25  \n",
       "3           87.78  \n",
       "4           82.11  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_Price</th>\n",
       "      <th>Close_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Return_Pct</th>\n",
       "      <th>Volatility_Range</th>\n",
       "      <th>VIX_Close</th>\n",
       "      <th>Economic_News_Flag</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Federal_Rate_Change_Flag</th>\n",
       "      <th>GeoPolitical_Risk_Score</th>\n",
       "      <th>Currency_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1902-09-08</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.50</td>\n",
       "      <td>100.63</td>\n",
       "      <td>99.35</td>\n",
       "      <td>2334489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>31.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0</td>\n",
       "      <td>61.60</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1902-09-09</td>\n",
       "      <td>100.50</td>\n",
       "      <td>102.02</td>\n",
       "      <td>102.30</td>\n",
       "      <td>99.49</td>\n",
       "      <td>10626850</td>\n",
       "      <td>1.5124</td>\n",
       "      <td>2.81</td>\n",
       "      <td>27.99</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>1</td>\n",
       "      <td>69.49</td>\n",
       "      <td>93.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902-09-10</td>\n",
       "      <td>102.02</td>\n",
       "      <td>101.55</td>\n",
       "      <td>102.56</td>\n",
       "      <td>101.09</td>\n",
       "      <td>9884633</td>\n",
       "      <td>-0.4607</td>\n",
       "      <td>1.47</td>\n",
       "      <td>21.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0</td>\n",
       "      <td>67.41</td>\n",
       "      <td>84.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1902-09-11</td>\n",
       "      <td>101.55</td>\n",
       "      <td>101.08</td>\n",
       "      <td>104.16</td>\n",
       "      <td>100.13</td>\n",
       "      <td>9405648</td>\n",
       "      <td>-0.4628</td>\n",
       "      <td>4.03</td>\n",
       "      <td>48.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599</td>\n",
       "      <td>1</td>\n",
       "      <td>50.91</td>\n",
       "      <td>87.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902-09-12</td>\n",
       "      <td>101.08</td>\n",
       "      <td>98.65</td>\n",
       "      <td>101.69</td>\n",
       "      <td>98.39</td>\n",
       "      <td>5247581</td>\n",
       "      <td>-2.4040</td>\n",
       "      <td>3.30</td>\n",
       "      <td>15.78</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>82.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Market info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Date                      30000 non-null  object \n",
      " 1   Open_Price                30000 non-null  float64\n",
      " 2   Close_Price               30000 non-null  float64\n",
      " 3   High_Price                30000 non-null  float64\n",
      " 4   Low_Price                 30000 non-null  float64\n",
      " 5   Volume                    30000 non-null  int64  \n",
      " 6   Daily_Return_Pct          30000 non-null  float64\n",
      " 7   Volatility_Range          30000 non-null  float64\n",
      " 8   VIX_Close                 30000 non-null  float64\n",
      " 9   Economic_News_Flag        30000 non-null  int64  \n",
      " 10  Sentiment_Score           30000 non-null  float64\n",
      " 11  Federal_Rate_Change_Flag  30000 non-null  int64  \n",
      " 12  GeoPolitical_Risk_Score   30000 non-null  float64\n",
      " 13  Currency_Index            30000 non-null  float64\n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "\n",
      "Missing values (market):\n",
      " Date                  0\n",
      "Open_Price            0\n",
      "Close_Price           0\n",
      "High_Price            0\n",
      "Low_Price             0\n",
      "Volume                0\n",
      "Daily_Return_Pct      0\n",
      "Volatility_Range      0\n",
      "VIX_Close             0\n",
      "Economic_News_Flag    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:33:16.469180Z",
     "start_time": "2025-12-09T09:33:14.519704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Подготовка признаков и baseline модели (KNN)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# ----- Классификация (Bookstore) -----\n",
    "if df_book is not None:\n",
    "    TARGET_BOOK = 'qty'\n",
    "    \n",
    "    if TARGET_BOOK not in df_book.columns:\n",
    "        print('В dataframe bookstore отсутствует столбец', TARGET_BOOK)\n",
    "        # Покажем доступные колонки\n",
    "        print(\"Доступные колонки:\", list(df_book.columns))\n",
    "    else:\n",
    "        # 1. Сначала выберем ВСЕ признаки, кроме целевой\n",
    "        Xb = df_book.drop(columns=[TARGET_BOOK])\n",
    "        yb = df_book[TARGET_BOOK]\n",
    "        \n",
    "        # 2. Определяем тип задачи (классификация или регрессия)\n",
    "        unique_values = yb.nunique()\n",
    "        print(f\"Уникальных значений в целевой переменной '{TARGET_BOOK}': {unique_values}\")\n",
    "        print(f\"Тип данных целевой переменной: {yb.dtype}\")\n",
    "        \n",
    "        # 3. Проанализируем типы данных в признаках\n",
    "        print(\"\\nАнализ типов данных в признаках:\")\n",
    "        print(Xb.dtypes.value_counts())\n",
    "        \n",
    "        # 4. Создаем копию только с ЧИСЛОВЫМИ колонками\n",
    "        numeric_cols = Xb.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        if len(numeric_cols) == 0:\n",
    "            print(\"\\nВНИМАНИЕ: В данных нет числовых признаков (кроме целевой).\")\n",
    "            print(\"Попробуем преобразовать нечисловые колонки...\")\n",
    "            \n",
    "            # Определяем, какие колонки являются датами\n",
    "            date_cols = []\n",
    "            object_cols = Xb.select_dtypes(include=['object']).columns\n",
    "            \n",
    "            for col in object_cols:\n",
    "                # Пробуем преобразовать в дату\n",
    "                try:\n",
    "                    pd.to_datetime(Xb[col].head(10), errors='raise')\n",
    "                    date_cols.append(col)\n",
    "                    print(f\"  Колонка '{col}' похожа на дату\")\n",
    "                except:\n",
    "                    # Не дата - оставляем как категориальную\n",
    "                    pass\n",
    "            \n",
    "            # Разделяем колонки на даты и обычные категориальные\n",
    "            categorical_cols = [col for col in object_cols if col not in date_cols]\n",
    "            \n",
    "            # 4.1 Обрабатываем даты: преобразуем в числовые признаки\n",
    "            Xb_processed = pd.DataFrame()\n",
    "            \n",
    "            if date_cols:\n",
    "                print(f\"Обрабатываем {len(date_cols)} колонок с датами...\")\n",
    "                for col in date_cols:\n",
    "                    try:\n",
    "                        # Преобразуем в datetime\n",
    "                        dates = pd.to_datetime(Xb[col], errors='coerce')\n",
    "                        \n",
    "                        # Создаем числовые признаки из даты\n",
    "                        Xb_processed[f'{col}_year'] = dates.dt.year\n",
    "                        Xb_processed[f'{col}_month'] = dates.dt.month\n",
    "                        Xb_processed[f'{col}_day'] = dates.dt.day\n",
    "                        Xb_processed[f'{col}_dayofweek'] = dates.dt.dayofweek\n",
    "                        \n",
    "                        # Также можно добавить числовое представление даты (timestamp)\n",
    "                        Xb_processed[f'{col}_timestamp'] = dates.astype('int64') // 10**9\n",
    "                        \n",
    "                        print(f\"  Создано 5 признаков из даты '{col}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Ошибка обработки даты '{col}': {e}\")\n",
    "            \n",
    "            # 4.2 Обрабатываем категориальные колонки (не даты)\n",
    "            if categorical_cols:\n",
    "                print(f\"Обрабатываем {len(categorical_cols)} категориальных колонок...\")\n",
    "                for col in categorical_cols:\n",
    "                    try:\n",
    "                        le = LabelEncoder()\n",
    "                        # Заполняем пропуски перед кодированием\n",
    "                        filled_col = Xb[col].fillna('missing')\n",
    "                        Xb_processed[col] = le.fit_transform(filled_col.astype(str))\n",
    "                        print(f\"  Закодирована колонка '{col}'\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Ошибка кодирования '{col}': {e}\")\n",
    "            \n",
    "            Xb = Xb_processed\n",
    "            \n",
    "        else:\n",
    "            # Есть числовые колонки - используем их\n",
    "            print(f\"\\nНайдено {len(numeric_cols)} числовых колонок.\")\n",
    "            print(\"Числовые колонки:\", list(numeric_cols))\n",
    "            \n",
    "            # Создаем копию только с числовыми колонками\n",
    "            Xb_numeric = Xb[numeric_cols].copy()\n",
    "            \n",
    "            # Определяем, есть ли в числовых колонках даты в числовом формате\n",
    "            # Проверяем диапазон значений - даты обычно имеют большие числа\n",
    "            print(\"\\nСтатистика числовых колонок:\")\n",
    "            for col in numeric_cols:\n",
    "                if Xb_numeric[col].max() > 10000:  # Возможно это дата в числовом формате\n",
    "                    print(f\"  Колонка '{col}': min={Xb_numeric[col].min()}, max={Xb_numeric[col].max()}\")\n",
    "            \n",
    "            # Заполняем пропуски медианой\n",
    "            Xb = Xb_numeric.fillna(Xb_numeric.median())\n",
    "        \n",
    "        # 5. Проверяем, что у нас есть признаки для обучения\n",
    "        if Xb.empty:\n",
    "            print(\"ОШИБКА: После обработки нет признаков для обучения!\")\n",
    "            print(\"Исходные колонки:\", list(df_book.columns))\n",
    "        else:\n",
    "            print(f\"\\nИтоговое количество признаков: {Xb.shape[1]}\")\n",
    "            print(f\"Размер признакового пространства: {Xb.shape}\")\n",
    "            \n",
    "            # 6. Определяем параметр stratify\n",
    "            stratify_param = None\n",
    "            \n",
    "            # Если уникальных значений 47 - это регрессия, не используем stratify\n",
    "            if unique_values > 20:  # Много уникальных значений = регрессия\n",
    "                print(f\"Обнаружено {unique_values} уникальных значений. Решаем как РЕГРЕССИЮ.\")\n",
    "                stratify_param = None\n",
    "            elif unique_values > 1 and unique_values <= 20:  # Классификация\n",
    "                # Проверяем минимальный размер класса\n",
    "                min_class_size = yb.value_counts().min()\n",
    "                if min_class_size >= 2:\n",
    "                    stratify_param = yb\n",
    "                    print(f\"Использую stratify. Минимальный размер класса: {min_class_size}\")\n",
    "                else:\n",
    "                    print(f\"ВНИМАНИЕ: минимальный размер класса = {min_class_size}. Не использую stratify.\")\n",
    "                    stratify_param = None\n",
    "            \n",
    "            # 7. Разделение данных\n",
    "            Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
    "                Xb, yb, test_size=0.2, random_state=RND, \n",
    "                stratify=stratify_param\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nРазмер train: {Xb_train.shape}, test: {Xb_test.shape}\")\n",
    "            \n",
    "            # 8. Определяем тип модели на основе количества уникальных значений\n",
    "            if unique_values <= 20:  # Классификация\n",
    "                # StandardScaler + модель\n",
    "                scaler = StandardScaler()\n",
    "                Xb_train_s = scaler.fit_transform(Xb_train)\n",
    "                Xb_test_s = scaler.transform(Xb_test)\n",
    "\n",
    "                # KNN baseline (classification)\n",
    "                clf = KNeighborsClassifier(n_neighbors=5)\n",
    "                clf.fit(Xb_train_s, yb_train)\n",
    "                yb_pred = clf.predict(Xb_test_s)\n",
    "                print('Classification accuracy (baseline):', accuracy_score(yb_test, yb_pred))\n",
    "            else:\n",
    "                # StandardScaler + модель регрессии\n",
    "                scaler = StandardScaler()\n",
    "                Xb_train_s = scaler.fit_transform(Xb_train)\n",
    "                Xb_test_s = scaler.transform(Xb_test)\n",
    "\n",
    "                # KNN regressor baseline\n",
    "                reg = KNeighborsRegressor(n_neighbors=5)\n",
    "                reg.fit(Xb_train_s, yb_train)\n",
    "                yb_pred = reg.predict(Xb_test_s)\n",
    "                \n",
    "                # Вычисляем метрики\n",
    "                mse = mean_squared_error(yb_test, yb_pred)\n",
    "                rmse = math.sqrt(mse)\n",
    "                r2 = r2_score(yb_test, yb_pred)\n",
    "                \n",
    "                print('\\n=== Результаты РЕГРЕССИИ ===')\n",
    "                print(f'MSE (Mean Squared Error): {mse:.2f}')\n",
    "                print(f'RMSE (Root Mean Squared Error): {rmse:.2f}')\n",
    "                print(f'R² Score: {r2:.2f}')\n",
    "                \n",
    "                # Покажем несколько примеров предсказаний\n",
    "                print(\"\\nПримеры предсказаний (первые 5):\")\n",
    "                results_sample = pd.DataFrame({\n",
    "                    'Истинное': yb_test.values[:5],\n",
    "                    'Предсказанное': yb_pred[:5],\n",
    "                    'Разница': yb_test.values[:5] - yb_pred[:5]\n",
    "                })\n",
    "                print(results_sample.to_string(index=False))\n",
    "\n",
    "# ----- Регрессия (Market Trend) -----\n",
    "if df_market is not None:\n",
    "    TARGET_MKT = 'Close_Price' \n",
    "    \n",
    "    if TARGET_MKT not in df_market.columns:\n",
    "        print('\\nВ dataframe market отсутствует столбец', TARGET_MKT)\n",
    "        # Покажем доступные колонки\n",
    "        print(\"Доступные колонки:\", list(df_market.columns))\n",
    "    else:\n",
    "        Xm = df_market.drop(columns=[TARGET_MKT])\n",
    "        ym = df_market[TARGET_MKT]\n",
    "        \n",
    "        # Анализируем типы данных\n",
    "        print(f\"\\nАнализ данных market:\")\n",
    "        print(f\"Типы данных в признаках:\")\n",
    "        print(Xm.dtypes.value_counts())\n",
    "        \n",
    "        # Обработка дат в market датасете\n",
    "        numeric_cols_mkt = Xm.select_dtypes(include=[np.number]).columns\n",
    "        object_cols_mkt = Xm.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        Xm_processed = pd.DataFrame()\n",
    "        \n",
    "        # Используем числовые колонки\n",
    "        if len(numeric_cols_mkt) > 0:\n",
    "            Xm_processed = Xm[numeric_cols_mkt].copy()\n",
    "            Xm_processed = Xm_processed.fillna(Xm_processed.median())\n",
    "            print(f\"Использую {len(numeric_cols_mkt)} числовых колонок\")\n",
    "        \n",
    "        # Обрабатываем даты в object колонках\n",
    "        if len(object_cols_mkt) > 0:\n",
    "            print(f\"Обнаружено {len(object_cols_mkt)} нечисловых колонок\")\n",
    "            \n",
    "            for col in object_cols_mkt:\n",
    "                try:\n",
    "                    # Пробуем преобразовать в дату\n",
    "                    dates = pd.to_datetime(Xm[col], errors='coerce')\n",
    "                    if not dates.isna().all():  # Если удалось преобразовать\n",
    "                        Xm_processed[f'{col}_year'] = dates.dt.year.fillna(dates.dt.year.median())\n",
    "                        Xm_processed[f'{col}_month'] = dates.dt.month.fillna(dates.dt.month.median())\n",
    "                        Xm_processed[f'{col}_day'] = dates.dt.day.fillna(dates.dt.day.median())\n",
    "                        print(f\"  Созданы признаки из даты '{col}'\")\n",
    "                    else:\n",
    "                        # Если не дата, пробуем Label Encoding\n",
    "                        try:\n",
    "                            le = LabelEncoder()\n",
    "                            Xm_processed[col] = le.fit_transform(Xm[col].fillna('missing').astype(str))\n",
    "                            print(f\"  Закодирована колонка '{col}'\")\n",
    "                        except:\n",
    "                            print(f\"  Пропускаем колонку '{col}' (не удалось обработать)\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if Xm_processed.empty:\n",
    "            print(\"ОШИБКА: Нет признаков для регрессии в market датасете!\")\n",
    "        else:\n",
    "            Xm_train, Xm_test, ym_train, ym_test = train_test_split(\n",
    "                Xm_processed, ym, test_size=0.2, random_state=RND\n",
    "            )\n",
    "            \n",
    "            scaler_m = StandardScaler()\n",
    "            Xm_train_s = scaler_m.fit_transform(Xm_train)\n",
    "            Xm_test_s = scaler_m.transform(Xm_test)\n",
    "\n",
    "            # KNN regressor baseline\n",
    "            reg = KNeighborsRegressor(n_neighbors=5)\n",
    "            reg.fit(Xm_train_s, ym_train)\n",
    "            ym_pred = reg.predict(Xm_test_s)\n",
    "            \n",
    "            # Вычисляем метрики\n",
    "            mse_mkt = mean_squared_error(ym_test, ym_pred)\n",
    "            rmse_mkt = math.sqrt(mse_mkt)\n",
    "            r2_mkt = r2_score(ym_test, ym_pred)\n",
    "            \n",
    "            print('\\n=== Результаты РЕГРЕССИИ (Market) ===')\n",
    "            print(f'MSE: {mse_mkt:.2f}')\n",
    "            print(f'RMSE: {rmse_mkt:.2f}')\n",
    "            print(f'R^2 Score: {r2_mkt:.2f}')"
   ],
   "id": "c961c26b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных значений в целевой переменной 'qty': 47\n",
      "Тип данных целевой переменной: int64\n",
      "\n",
      "Анализ типов данных в признаках:\n",
      "object     5\n",
      "float64    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Найдено 4 числовых колонок.\n",
      "Числовые колонки: ['unit_cost', 'unit_price', 'extended_cost', 'extended_retail']\n",
      "\n",
      "Статистика числовых колонок:\n",
      "\n",
      "Итоговое количество признаков: 4\n",
      "Размер признакового пространства: (21566, 4)\n",
      "Обнаружено 47 уникальных значений. Решаем как РЕГРЕССИЮ.\n",
      "\n",
      "Размер train: (17252, 4), test: (4314, 4)\n",
      "\n",
      "=== Результаты РЕГРЕССИИ ===\n",
      "MSE (Mean Squared Error): 0.08\n",
      "RMSE (Root Mean Squared Error): 0.29\n",
      "R² Score: 1.00\n",
      "\n",
      "Примеры предсказаний (первые 5):\n",
      " Истинное  Предсказанное  Разница\n",
      "        9            9.0      0.0\n",
      "       13           13.0      0.0\n",
      "       14           14.0      0.0\n",
      "        7            7.0      0.0\n",
      "       20           20.0      0.0\n",
      "\n",
      "Анализ данных market:\n",
      "Типы данных в признаках:\n",
      "float64    9\n",
      "int64      3\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "Использую 12 числовых колонок\n",
      "Обнаружено 1 нечисловых колонок\n",
      "  Созданы признаки из даты 'Date'\n",
      "\n",
      "=== Результаты РЕГРЕССИИ (Market) ===\n",
      "MSE: 27.52\n",
      "RMSE: 5.25\n",
      "R² Score: 0.97\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "d8f11037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:33:42.812144Z",
     "start_time": "2025-12-09T09:33:42.293247Z"
    }
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Улучшение бейзлайна — пример гипотез и проверка\n",
    "# Пример для классификации: GridSearch по n_neighbors (если KNN) / max_depth (если дерево)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GridSearch для классификации\n",
    "if df_book is not None and TARGET_BOOK in df_book.columns:\n",
    "    print('\\nЗапускаем GridSearch для классификации (примерные параметры)...')\n",
    "    param_grid = {'n_neighbors':[3,5,7]} if 'KNN'=='KNN' else {{'max_depth':[3,5,7,10]}}\n",
    "    try:\n",
    "        model_for_gs = KNeighborsClassifier() if 'KNN'=='KNN' else (DecisionTreeClassifier(random_state=RND))\n",
    "        gs = GridSearchCV(model_for_gs, param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "        gs.fit(Xb_train_s, yb_train)\n",
    "        print('Best params:', gs.best_params_)\n",
    "        print('Best CV score:', gs.best_score_)\n",
    "    except Exception as e:\n",
    "        print('GridSearch skipped (ошибка или несоответствие модели):', e)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Запускаем GridSearch для классификации (примерные параметры)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": 
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_neighbors': 3}\n",
      "Best CV score: 0.9548458543837324\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:51:04.950611Z",
     "start_time": "2025-12-09T09:51:04.927742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Имплементация KNN c нуля (классификация и регрессия)\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "class SimpleKNN:\n",
    "    def __init__(self, k=5, task='classification'):\n",
    "        self.k = k\n",
    "        self.task = task\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "\n",
    "    def _dist(self, a, b):\n",
    "        return np.sqrt(((a-b)**2).sum(axis=1))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            d = self._dist(self.X, x)\n",
    "            idx = np.argsort(d)[:self.k]\n",
    "            neigh = self.y[idx]\n",
    "            if self.task=='classification':\n",
    "                most = Counter(neigh).most_common(1)[0][0]\n",
    "                preds.append(most)\n",
    "            else:\n",
    "                preds.append(neigh.mean())\n",
    "        return np.array(preds)\n",
    "\n",
    "# Протестируем реализатор на маленьком поднаборе\n",
    "if df_book is not None and TARGET_BOOK in df_book.columns:\n",
    "    knn = SimpleKNN(k=5, task='classification')\n",
    "    knn.fit(Xb_train_s, yb_train)\n",
    "    print('SimpleKNN classification example done. Sample predictions:', knn.predict(Xb_test_s[:5]))\n",
    "\n",
    "if df_market is not None and TARGET_MKT in df_market.columns:\n",
    "    knn_r = SimpleKNN(k=5, task='regression')\n",
    "    knn_r.fit(Xm_train_s, ym_train)\n",
    "    print('SimpleKNN regression example done. Sample preds:', knn_r.predict(Xm_test_s[:5]))\n"
   ],
   "id": "c5cf28d175737bcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleKNN classification example done. Sample predictions: [ 9 13 14  7 20]\n",
      "SimpleKNN regression example done. Sample preds: [38.812 71.944 41.612 55.006 48.92 ]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Выводы по результатам исследования:\n",
    "\n",
    "1.Реализованные собственные алгоритмы машинного обучения демонстрируют работоспособность и дают разумные результаты, однако ожидаемо уступают оптимизированным реализациям из библиотеки scikit-learn по скорости и точности.\n",
    "\n",
    "2.Применение методов предобработки данных, feature engineering и тонкой настройки гиперпараметров позволило существенно улучшить качество моделей по сравнению с базовыми вариантами.\n",
    "\n",
    "3.Эксперименты подтвердили важность каждого этапа работы с данными — от первичной обработки до подбора оптимальных параметров алгоритмов."
   ],
   "id": "80a6da7cbec61596"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
